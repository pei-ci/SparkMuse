{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "87520192",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://ldzhangyx.github.io/2020/01/13/music-practice/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e43f8f28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lakh Pianoroll Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3d39462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\fluid\\bin\\libfluidsynth-3.dll\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "import os\n",
    "import os.path\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import pypianoroll\n",
    "from pypianoroll import Multitrack, Track, StandardTrack\n",
    "from tqdm import tqdm\n",
    "from livelossplot import PlotLosses\n",
    "from livelossplot.outputs import MatplotlibPlot\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ad88b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_root = Path(\"D:/midi_data/lpd_5/lpd_5_cleansed/\")\n",
    "id_list = []\n",
    "\"\"\"for path in os.listdir(\"D:/midi_data/amg\"):\n",
    "    filepath = os.path.join(\"D:/midi_data/amg\", path)\n",
    "    if os.path.isfile(filepath):\n",
    "        with open(filepath) as f:\n",
    "            id_list.extend([line.rstrip() for line in f])\n",
    "\"\"\"\n",
    "filepath = os.path.join(\"D:/midi_data/amg\", \"project/Electronic/Electronic_Strong_Negative.txt\")\n",
    "if os.path.isfile(filepath):\n",
    "    with open(filepath) as f:\n",
    "        id_list.extend([line.rstrip() for line in f])\n",
    "id_list = list(set(id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c6178f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "n_tracks = 5  # number of tracks\n",
    "n_pitches = 72  # number of pitches\n",
    "lowest_pitch = 24  # MIDI note number of the lowest pitch\n",
    "n_samples_per_song = 8  # number of samples to extract from each song in the datset\n",
    "n_measures = 4  # number of measures per sample\n",
    "beat_resolution = 4  # temporal resolution of a beat (in timestep)\n",
    "programs = [0, 0, 25, 33, 48]  # program number for each track\n",
    "is_drums = [True, False, False, False, False]  # drum indicator for each track\n",
    "track_names = ['Drums', 'Piano', 'Guitar', 'Bass', 'Strings']  # name of each track\n",
    "tempo = 100\n",
    "\n",
    "# Training\n",
    "batch_size = 16\n",
    "latent_dim = 128\n",
    "n_steps = 17000\n",
    "\n",
    "# Sampling\n",
    "sample_interval = 100  # interval to run the sampler (in step)\n",
    "n_samples = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67904154",
   "metadata": {},
   "outputs": [],
   "source": [
    "measure_resolution = 4 * beat_resolution\n",
    "tempo_array = np.full((4 * 4 * measure_resolution, 1), tempo)\n",
    "assert 24 % beat_resolution == 0, (\n",
    "    \"beat_resolution must be a factor of 24 (the beat resolution used in \"\n",
    "    \"the source dataset).\"\n",
    ")\n",
    "assert len(programs) == len(is_drums) and len(programs) == len(track_names), (\n",
    "    \"Lengths of programs, is_drums and track_names must be the same.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68a0213a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def msd_id_to_dirs(msd_id):\n",
    "    \"\"\"Given an MSD ID, generate the path prefix.\n",
    "    E.g. TRABCD12345678 -> A/B/C/TRABCD12345678\"\"\"\n",
    "    return os.path.join(msd_id[2], msd_id[3], msd_id[4], msd_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ec47252",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GeneraterBlock(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
    "        super().__init__()\n",
    "        self.transconv = torch.nn.ConvTranspose3d(in_dim, out_dim, kernel, stride)\n",
    "        self.batchnorm = torch.nn.BatchNorm3d(out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transconv(x)\n",
    "        x = self.batchnorm(x)\n",
    "        return torch.nn.functional.relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ceda26f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(torch.nn.Module):\n",
    "    \"\"\"A convolutional neural network (CNN) based generator. The generator takes\n",
    "    as input a latent vector and outputs a fake sample.\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.transconv0 = GeneraterBlock(latent_dim, 256, (4, 1, 1), (4, 1, 1))\n",
    "        self.transconv1 = GeneraterBlock(256, 128, (1, 4, 1), (1, 4, 1))\n",
    "        self.transconv2 = GeneraterBlock(128, 64, (1, 1, 4), (1, 1, 4))\n",
    "        self.transconv3 = GeneraterBlock(64, 32, (1, 1, 3), (1, 1, 1))\n",
    "        self.transconv4 = torch.nn.ModuleList([\n",
    "            GeneraterBlock(32, 16, (1, 4, 1), (1, 4, 1))\n",
    "            for _ in range(n_tracks)\n",
    "        ])\n",
    "        self.transconv5 = torch.nn.ModuleList([\n",
    "            GeneraterBlock(16, 1, (1, 1, 12), (1, 1, 12))\n",
    "            for _ in range(n_tracks)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, latent_dim, 1, 1, 1)\n",
    "        x = self.transconv0(x)\n",
    "        x = self.transconv1(x)\n",
    "        x = self.transconv2(x)\n",
    "        x = self.transconv3(x)\n",
    "        x = [transconv(x) for transconv in self.transconv4]\n",
    "        x = torch.cat([transconv(x_) for x_, transconv in zip(x, self.transconv5)], 1)\n",
    "        x = x.view(-1, n_tracks, n_measures * measure_resolution, n_pitches)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e090bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LayerNorm(torch.nn.Module):\n",
    "    \"\"\"An implementation of Layer normalization that does not require size\n",
    "    information. Copied from https://github.com/pytorch/pytorch/issues/1959.\"\"\"\n",
    "    def __init__(self, n_features, eps=1e-5, affine=True):\n",
    "        super().__init__()\n",
    "        self.n_features = n_features\n",
    "        self.affine = affine\n",
    "        self.eps = eps\n",
    "        if self.affine:\n",
    "            self.gamma = torch.nn.Parameter(torch.Tensor(n_features).uniform_())\n",
    "            self.beta = torch.nn.Parameter(torch.zeros(n_features))\n",
    "\n",
    "    def forward(self, x):\n",
    "        shape = [-1] + [1] * (x.dim() - 1)\n",
    "        mean = x.view(x.size(0), -1).mean(1).view(*shape)\n",
    "        std = x.view(x.size(0), -1).std(1).view(*shape)\n",
    "        y = (x - mean) / (std + self.eps)\n",
    "        if self.affine:\n",
    "            shape = [1, -1] + [1] * (x.dim() - 2)\n",
    "            y = self.gamma.view(*shape) * y + self.beta.view(*shape)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f16b569e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiscriminatorBlock(torch.nn.Module):\n",
    "    def __init__(self, in_dim, out_dim, kernel, stride):\n",
    "        super().__init__()\n",
    "        self.transconv = torch.nn.Conv3d(in_dim, out_dim, kernel, stride)\n",
    "        self.layernorm = LayerNorm(out_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.transconv(x)\n",
    "        x = self.layernorm(x)\n",
    "        return torch.nn.functional.leaky_relu(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f198183",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(torch.nn.Module):\n",
    "    \"\"\"A convolutional neural network (CNN) based discriminator. The\n",
    "    discriminator takes as input either a real sample (in the training data) or\n",
    "    a fake sample (generated by the generator) and outputs a scalar indicating\n",
    "    its authentity.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv0 = torch.nn.ModuleList([\n",
    "            DiscriminatorBlock(1, 16, (1, 1, 12), (1, 1, 12)) for _ in range(n_tracks)\n",
    "        ])\n",
    "        self.conv1 = torch.nn.ModuleList([\n",
    "            DiscriminatorBlock(16, 16, (1, 4, 1), (1, 4, 1)) for _ in range(n_tracks)\n",
    "        ])\n",
    "        self.conv2 = DiscriminatorBlock(16 * n_tracks, 64, (1, 1, 3), (1, 1, 1))\n",
    "        self.conv3 = DiscriminatorBlock(64, 64, (1, 1, 4), (1, 1, 4))\n",
    "        self.conv4 = DiscriminatorBlock(64, 128, (1, 4, 1), (1, 4, 1))\n",
    "        self.conv5 = DiscriminatorBlock(128, 128, (2, 1, 1), (1, 1, 1))\n",
    "        self.conv6 = DiscriminatorBlock(128, 256, (3, 1, 1), (3, 1, 1))\n",
    "        self.dense = torch.nn.Linear(256, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, n_tracks, n_measures, measure_resolution, n_pitches)\n",
    "        x = [conv(x[:, [i]]) for i, conv in enumerate(self.conv0)]\n",
    "        x = torch.cat([conv(x_) for x_, conv in zip(x, self.conv1)], 1)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)          \n",
    "        x = self.conv4(x)\n",
    "        x = self.conv5(x)\n",
    "        x = self.conv6(x)\n",
    "        x = x.view(-1, 256)\n",
    "        x = self.dense(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e729db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient_penalty(discriminator, real_samples, fake_samples):\n",
    "    \"\"\"Compute the gradient penalty for regularization. Intuitively, the\n",
    "    gradient penalty help stablize the magnitude of the gradients that the\n",
    "    discriminator provides to the generator, and thus help stablize the training\n",
    "    of the generator.\"\"\"\n",
    "    # Get random interpolations between real and fake samples\n",
    "    alpha = torch.rand(real_samples.size(0), 1, 1, 1).cuda()\n",
    "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples))\n",
    "    interpolates = interpolates.requires_grad_(True)\n",
    "    # Get the discriminator output for the interpolations\n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    # Get gradients w.r.t. the interpolations\n",
    "    fake = torch.ones(real_samples.size(0), 1).cuda()\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    # Compute gradient penalty\n",
    "    gradients = gradients.view(gradients.size(0), -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    return gradient_penalty "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2008a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_step(d_optimizer, g_optimizer, real_samples):\n",
    "    \"\"\"Train the networks for one step.\"\"\"\n",
    "    \n",
    "    latent = torch.randn(batch_size, latent_dim)\n",
    "\n",
    "    # Transfer data to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        real_samples = real_samples.cuda()\n",
    "        latent = latent.cuda()\n",
    "    \n",
    "    # === Train the discriminator ===\n",
    "    # Reset cached gradients to zero\n",
    "    d_optimizer.zero_grad()\n",
    "    # Get discriminator outputs for the real samples\n",
    "    prediction_real = discriminator(real_samples)\n",
    "    # Compute the loss function\n",
    "    # d_loss_real = torch.mean(torch.nn.functional.relu(1. - prediction_real))\n",
    "    d_loss_real = -torch.mean(prediction_real)\n",
    "    # Backpropagate the gradients\n",
    "    d_loss_real.backward()\n",
    "    \n",
    "    # Generate fake samples with the generator\n",
    "    fake_samples = generator(latent)\n",
    "    # Get discriminator outputs for the fake samples\n",
    "    prediction_fake_d = discriminator(fake_samples.detach())\n",
    "    # Compute the loss function\n",
    "    # d_loss_fake = torch.mean(torch.nn.functional.relu(1. + prediction_fake_d))\n",
    "    d_loss_fake = torch.mean(prediction_fake_d)\n",
    "    # Backpropagate the gradients\n",
    "    d_loss_fake.backward()\n",
    "\n",
    "    # Compute gradient penalty\n",
    "    gradient_penalty = 10.0 * compute_gradient_penalty(\n",
    "        discriminator, real_samples.data, fake_samples.data)\n",
    "    # Backpropagate the gradients\n",
    "    gradient_penalty.backward()\n",
    "\n",
    "    # Update the weights\n",
    "    d_optimizer.step()\n",
    "    \n",
    "    # === Train the generator ===\n",
    "    # Reset cached gradients to zero\n",
    "    g_optimizer.zero_grad()\n",
    "    # Get discriminator outputs for the fake samples\n",
    "    prediction_fake_g = discriminator(fake_samples)\n",
    "    # Compute the loss function\n",
    "    g_loss = -torch.mean(prediction_fake_g)\n",
    "    # Backpropagate the gradients\n",
    "    g_loss.backward()\n",
    "    # Update the weights\n",
    "    g_optimizer.step()\n",
    "\n",
    "    return d_loss_real + d_loss_fake, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3bd3dfdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 13/13 [00:01<00:00,  9.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully collect 16 samples from 13 songs\n",
      "Data shape : (16, 5, 64, 72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "# Iterate over all the songs in the ID list\n",
    "for msd_id in tqdm(id_list):\n",
    "    # Load the multitrack as a pypianoroll.Multitrack instance\n",
    "    song_dir = dataset_root / msd_id_to_dirs(msd_id)\n",
    "    multitrack = pypianoroll.load(song_dir / os.listdir(song_dir)[0])\n",
    "    #multitrack = pypianoroll.read(song_dir / os.listdir(song_dir)[0])\n",
    "    # Binarize the pianorolls\n",
    "    multitrack.binarize()\n",
    "    # Downsample the pianorolls (shape: n_timesteps x n_pitches)\n",
    "    multitrack.set_resolution(beat_resolution)\n",
    "    # Stack the pianoroll (shape: n_tracks x n_timesteps x n_pitches)\n",
    "    pianoroll = (multitrack.stack() > 0)\n",
    "    # Get the target pitch range only\n",
    "    pianoroll = pianoroll[:, :, lowest_pitch:lowest_pitch + n_pitches]\n",
    "    # Calculate the total measures\n",
    "    n_total_measures = multitrack.get_max_length() // measure_resolution\n",
    "    candidate = n_total_measures - n_measures\n",
    "    target_n_samples = min(n_total_measures // n_measures, n_samples_per_song)\n",
    "    # Randomly select a number of phrases from the multitrack pianoroll\n",
    "    for idx in np.random.choice(candidate, target_n_samples, False):\n",
    "        start = idx * measure_resolution\n",
    "        end = (idx + n_measures) * measure_resolution\n",
    "        # Skip the samples where some track(s) has too few notes\n",
    "        if (pianoroll.sum(axis=(1, 2)) < 10).any():\n",
    "            continue\n",
    "        data.append(pianoroll[:, start:end])\n",
    "# Stack all the collected pianoroll segments into one big array\n",
    "random.shuffle(data)\n",
    "data = np.stack(data)\n",
    "print(f\"Successfully collect {len(data)} samples from {len(id_list)} songs\")\n",
    "print(f\"Data shape : {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58b08a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "selected_data = []\n",
    "max = len(data)\n",
    "ind_list = list(range(0, max))\n",
    "n = 24\n",
    "if max < n:\n",
    "    n = max\n",
    "selected_ind = random.sample(ind_list, n)\n",
    "selected_ind = sorted(selected_ind)\n",
    "for ind in selected_ind:\n",
    "    selected_data.append(data[ind])\n",
    "selected_data = np.stack(selected_data)\n",
    "\n",
    "#data = torch.as_tensor(data, dtype=torch.float32)\n",
    "selected_data = torch.as_tensor(selected_data, dtype=torch.float32)\n",
    "dataset = torch.utils.data.TensorDataset(selected_data)\n",
    "data_loader = torch.utils.data.DataLoader(\n",
    "    dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "print(len(selected_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d77cc92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "(d_loss=-5.482748, g_loss= 0.321404):   1%| | 201/17000 [02:26<1:06:43,  4.20it/\u001b[A\n",
      "(d_loss=-4.591608, g_loss= 2.413984):   1%| | 202/17000 [02:26<1:06:43,  4.20it/\u001b[A\n",
      "(d_loss=-5.484363, g_loss= 3.141258):   1%| | 203/17000 [02:26<1:06:43,  4.20it/\u001b[A\n",
      "(d_loss=-5.484363, g_loss= 3.141258):   1%| | 204/17000 [02:26<1:05:32,  4.27it/\u001b[A\n",
      "(d_loss=-5.371173, g_loss= 3.643832):   1%| | 204/17000 [02:26<1:05:32,  4.27it/\u001b[A\n",
      "(d_loss=-6.236157, g_loss= 3.513911):   1%| | 205/17000 [02:26<1:05:31,  4.27it/\u001b[A\n",
      "(d_loss=-6.601859, g_loss= 0.638586):   1%| | 206/17000 [02:27<1:05:31,  4.27it/\u001b[A\n",
      "(d_loss=-4.671699, g_loss= 4.321382):   1%| | 207/17000 [02:27<1:05:31,  4.27it/\u001b[A\n",
      "(d_loss=-6.502062, g_loss= 4.431223):   1%| | 208/17000 [02:27<1:05:31,  4.27it/\u001b[A\n",
      "(d_loss=-6.502062, g_loss= 4.431223):   1%| | 209/17000 [02:27<1:04:42,  4.33it/\u001b[A\n",
      "(d_loss=-6.674587, g_loss= 2.458454):   1%| | 209/17000 [02:27<1:04:42,  4.33it/\u001b[A\n",
      "(d_loss=-4.619405, g_loss= 2.946209):   1%| | 210/17000 [02:28<1:04:41,  4.33it/\u001b[A\n",
      "(d_loss=-4.790051, g_loss= 3.228451):   1%| | 211/17000 [02:28<1:04:41,  4.33it/\u001b[A\n",
      "(d_loss=-4.823551, g_loss= 2.305088):   1%| | 212/17000 [02:28<1:04:41,  4.33it/\u001b[A\n",
      "(d_loss=-3.972878, g_loss= 1.792091):   1%| | 213/17000 [02:28<1:04:41,  4.33it/\u001b[A\n",
      "(d_loss=-3.972878, g_loss= 1.792091):   1%| | 214/17000 [02:28<1:03:57,  4.37it/\u001b[A\n",
      "(d_loss=-4.735919, g_loss= 3.136203):   1%| | 214/17000 [02:28<1:03:57,  4.37it/\u001b[A\n",
      "(d_loss=-6.178452, g_loss= 3.583980):   1%| | 215/17000 [02:29<1:03:57,  4.37it/\u001b[A\n",
      "(d_loss=-3.593978, g_loss= 2.224581):   1%| | 216/17000 [02:29<1:03:57,  4.37it/\u001b[A\n",
      "(d_loss=-4.241827, g_loss= 3.175686):   1%| | 217/17000 [02:29<1:03:56,  4.37it/\u001b[A\n",
      "(d_loss=-6.398518, g_loss= 4.716602):   1%| | 218/17000 [02:29<1:03:56,  4.37it/\u001b[A\n",
      "(d_loss=-6.398518, g_loss= 4.716602):   1%| | 219/17000 [02:29<1:03:15,  4.42it/\u001b[A\n",
      "(d_loss=-5.850959, g_loss= 3.487238):   1%| | 219/17000 [02:30<1:03:15,  4.42it/\u001b[A\n",
      "(d_loss=-7.023562, g_loss= 2.095153):   1%| | 220/17000 [02:30<1:03:14,  4.42it/\u001b[A\n",
      "(d_loss=-5.386326, g_loss= 2.684365):   1%| | 221/17000 [02:30<1:03:14,  4.42it/\u001b[A\n",
      "(d_loss=-6.407867, g_loss= 1.755328):   1%| | 222/17000 [02:30<1:03:14,  4.42it/\u001b[A\n",
      "(d_loss=-6.457784, g_loss=-2.567348):   1%| | 223/17000 [02:30<1:03:14,  4.42it/\u001b[A\n",
      "(d_loss=-6.457784, g_loss=-2.567348):   1%| | 224/17000 [02:30<1:02:57,  4.44it/\u001b[A\n",
      "(d_loss=-2.690560, g_loss= 0.066813):   1%| | 224/17000 [02:31<1:02:57,  4.44it/\u001b[A\n",
      "(d_loss=-2.901602, g_loss= 3.133008):   1%| | 225/17000 [02:31<1:02:57,  4.44it/\u001b[A\n",
      "(d_loss=-3.707084, g_loss= 4.463784):   1%| | 226/17000 [02:31<1:02:57,  4.44it/\u001b[A\n",
      "(d_loss=-5.205373, g_loss= 4.322544):   1%| | 227/17000 [02:31<1:02:57,  4.44it/\u001b[A\n",
      "(d_loss=-2.932863, g_loss= 1.515258):   1%| | 228/17000 [02:32<1:02:57,  4.44it/\u001b[A\n",
      "(d_loss=-2.932863, g_loss= 1.515258):   1%| | 229/17000 [02:32<1:02:41,  4.46it/\u001b[A\n",
      "(d_loss=-3.214284, g_loss= 1.883715):   1%| | 229/17000 [02:32<1:02:41,  4.46it/\u001b[A\n",
      "(d_loss=-3.869136, g_loss= 3.778414):   1%| | 230/17000 [02:32<1:02:41,  4.46it/\u001b[A\n",
      "(d_loss=-5.036894, g_loss= 3.454189):   1%| | 231/17000 [02:32<1:02:40,  4.46it/\u001b[A\n",
      "(d_loss=-4.207844, g_loss= 3.888850):   1%| | 232/17000 [02:32<1:02:40,  4.46it/\u001b[A\n",
      "(d_loss=-5.395091, g_loss= 4.800283):   1%| | 233/17000 [02:33<1:02:40,  4.46it/\u001b[A\n",
      "(d_loss=-5.395091, g_loss= 4.800283):   1%| | 234/17000 [02:33<1:02:25,  4.48it/\u001b[A\n",
      "(d_loss=-5.250674, g_loss= 3.320730):   1%| | 234/17000 [02:33<1:02:25,  4.48it/\u001b[A\n",
      "(d_loss=-5.373741, g_loss= 2.221098):   1%| | 235/17000 [02:33<1:02:25,  4.48it/\u001b[A\n",
      "(d_loss=-4.896687, g_loss= 4.321558):   1%| | 236/17000 [02:33<1:02:25,  4.48it/\u001b[A\n",
      "(d_loss=-6.905820, g_loss= 2.300914):   1%| | 237/17000 [02:34<1:02:25,  4.48it/\u001b[A\n",
      "(d_loss=-6.896877, g_loss= 3.708553):   1%| | 238/17000 [02:34<1:02:24,  4.48it/\u001b[A\n",
      "(d_loss=-6.896877, g_loss= 3.708553):   1%| | 239/17000 [02:34<1:02:07,  4.50it/\u001b[A\n",
      "(d_loss=-5.394645, g_loss= 4.960918):   1%| | 239/17000 [02:34<1:02:07,  4.50it/\u001b[A\n",
      "(d_loss=-6.320762, g_loss= 6.632392):   1%| | 240/17000 [02:34<1:02:07,  4.50it/\u001b[A\n",
      "(d_loss=-6.544077, g_loss= 4.519993):   1%| | 241/17000 [02:34<1:02:07,  4.50it/\u001b[A\n",
      "(d_loss=-5.594140, g_loss= 6.627628):   1%| | 242/17000 [02:35<1:02:06,  4.50it/\u001b[A\n",
      "(d_loss=-5.212610, g_loss= 5.164619):   1%| | 243/17000 [02:35<1:02:06,  4.50it/\u001b[A\n",
      "(d_loss=-5.212610, g_loss= 5.164619):   1%| | 244/17000 [02:35<1:02:08,  4.49it/\u001b[A\n",
      "(d_loss=-7.550784, g_loss= 7.504816):   1%| | 244/17000 [02:35<1:02:08,  4.49it/\u001b[A\n",
      "(d_loss=-6.143276, g_loss= 0.786692):   1%| | 245/17000 [02:35<1:02:08,  4.49it/\u001b[A\n",
      "(d_loss=-5.721567, g_loss= 0.598726):   1%| | 246/17000 [02:36<1:02:07,  4.49it/\u001b[A\n",
      "(d_loss=-5.034064, g_loss= 3.166789):   1%| | 247/17000 [02:36<1:02:07,  4.49it/\u001b[A\n",
      "(d_loss=-5.533772, g_loss= 4.716611):   1%| | 248/17000 [02:36<1:02:07,  4.49it/\u001b[A\n",
      "(d_loss=-5.533772, g_loss= 4.716611):   1%| | 249/17000 [02:36<1:02:16,  4.48it/\u001b[A\n",
      "(d_loss=-6.187542, g_loss= 5.457159):   1%| | 249/17000 [02:36<1:02:16,  4.48it/\u001b[A\n",
      "(d_loss=-6.168784, g_loss= 4.445767):   1%| | 250/17000 [02:36<1:02:16,  4.48it/\u001b[A\n",
      "(d_loss=-6.499849, g_loss= 1.023380):   1%| | 251/17000 [02:37<1:02:16,  4.48it/\u001b[A\n",
      "(d_loss=-3.657111, g_loss= 1.992456):   1%| | 252/17000 [02:37<1:02:16,  4.48it/\u001b[A\n",
      "(d_loss=-5.260696, g_loss= 3.833888):   1%| | 253/17000 [02:37<1:02:15,  4.48it/\u001b[A\n",
      "(d_loss=-5.260696, g_loss= 3.833888):   1%| | 254/17000 [02:37<1:02:09,  4.49it/\u001b[A\n",
      "(d_loss=-7.354732, g_loss= 2.552809):   1%| | 254/17000 [02:37<1:02:09,  4.49it/\u001b[A\n",
      "(d_loss=-4.906117, g_loss= 2.111821):   2%| | 255/17000 [02:38<1:02:09,  4.49it/\u001b[A\n",
      "(d_loss=-5.561560, g_loss= 3.650127):   2%| | 256/17000 [02:38<1:02:09,  4.49it/\u001b[A\n",
      "(d_loss=-6.867760, g_loss= 3.700799):   2%| | 257/17000 [02:38<1:02:08,  4.49it/\u001b[A\n",
      "(d_loss=-3.666277, g_loss= 2.920243):   2%| | 258/17000 [02:38<1:02:08,  4.49it/\u001b[A\n",
      "(d_loss=-3.666277, g_loss= 2.920243):   2%| | 259/17000 [02:38<1:02:00,  4.50it/\u001b[A\n",
      "(d_loss=-4.372274, g_loss= 3.162578):   2%| | 259/17000 [02:38<1:02:00,  4.50it/\u001b[A\n",
      "(d_loss=-6.844051, g_loss=-2.093958):   2%| | 260/17000 [02:39<1:02:00,  4.50it/\u001b[A\n",
      "(d_loss=-3.386077, g_loss= 0.362148):   2%| | 261/17000 [02:39<1:02:00,  4.50it/\u001b[A\n",
      "(d_loss=-4.421746, g_loss= 4.460632):   2%| | 262/17000 [02:39<1:02:00,  4.50it/\u001b[A\n",
      "(d_loss=-5.268678, g_loss= 5.384021):   2%| | 263/17000 [02:39<1:02:00,  4.50it/\u001b[A\n",
      "(d_loss=-5.268678, g_loss= 5.384021):   2%| | 264/17000 [02:39<1:02:08,  4.49it/\u001b[A\n",
      "(d_loss=-4.251904, g_loss= 3.770825):   2%| | 264/17000 [02:40<1:02:08,  4.49it/\u001b[A\n",
      "(d_loss=-5.042057, g_loss= 2.945685):   2%| | 265/17000 [02:40<1:02:08,  4.49it/\u001b[A\n",
      "(d_loss=-4.704898, g_loss= 2.139649):   2%| | 266/17000 [02:40<1:02:08,  4.49it/\u001b[A\n",
      "(d_loss=-5.140867, g_loss= 2.316572):   2%| | 267/17000 [02:40<1:02:07,  4.49it/\u001b[A\n",
      "(d_loss=-5.196127, g_loss= 3.091486):   2%| | 268/17000 [02:40<1:02:07,  4.49it/\u001b[A\n",
      "(d_loss=-5.196127, g_loss= 3.091486):   2%| | 269/17000 [02:40<1:01:57,  4.50it/\u001b[A\n",
      "(d_loss=-4.789098, g_loss= 3.990631):   2%| | 269/17000 [02:41<1:01:57,  4.50it/\u001b[A\n",
      "(d_loss=-6.733572, g_loss= 5.928062):   2%| | 270/17000 [02:41<1:01:57,  4.50it/\u001b[A\n",
      "(d_loss=-3.760747, g_loss= 3.725133):   2%| | 271/17000 [02:41<1:01:57,  4.50it/\u001b[A\n",
      "(d_loss=-4.773141, g_loss= 2.591287):   2%| | 272/17000 [02:41<1:01:56,  4.50it/\u001b[A\n",
      "(d_loss=-6.370345, g_loss= 2.170105):   2%| | 273/17000 [02:42<1:01:56,  4.50it/\u001b[A\n",
      "(d_loss=-6.370345, g_loss= 2.170105):   2%| | 274/17000 [02:42<1:01:53,  4.50it/\u001b[A\n",
      "(d_loss=-4.725712, g_loss= 3.843205):   2%| | 274/17000 [02:42<1:01:53,  4.50it/\u001b[A"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [18], line 57\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m real_samples \u001b[38;5;129;01min\u001b[39;00m data_loader:\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;66;03m# Train the neural networks\u001b[39;00m\n\u001b[0;32m     56\u001b[0m     generator\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 57\u001b[0m     d_loss, g_loss \u001b[38;5;241m=\u001b[39m train_one_step(d_optimizer, g_optimizer, real_samples[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Record smoothened loss values to LiveLoss logger\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "Cell \u001b[1;32mIn [12], line 33\u001b[0m, in \u001b[0;36mtrain_one_step\u001b[1;34m(d_optimizer, g_optimizer, real_samples)\u001b[0m\n\u001b[0;32m     30\u001b[0m d_loss_fake\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Compute gradient penalty\u001b[39;00m\n\u001b[1;32m---> 33\u001b[0m gradient_penalty \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10.0\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[43mcompute_gradient_penalty\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreal_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfake_samples\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Backpropagate the gradients\u001b[39;00m\n\u001b[0;32m     36\u001b[0m gradient_penalty\u001b[38;5;241m.\u001b[39mbackward()\n",
      "Cell \u001b[1;32mIn [11], line 14\u001b[0m, in \u001b[0;36mcompute_gradient_penalty\u001b[1;34m(discriminator, real_samples, fake_samples)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Get gradients w.r.t. the interpolations\u001b[39;00m\n\u001b[0;32m     13\u001b[0m fake \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones(real_samples\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m---> 14\u001b[0m gradients \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43md_interpolates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfake\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43monly_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[0;32m     21\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Compute gradient penalty\u001b[39;00m\n\u001b[0;32m     23\u001b[0m gradients \u001b[38;5;241m=\u001b[39m gradients\u001b[38;5;241m.\u001b[39mview(gradients\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\miniconda3\\lib\\site-packages\\torch\\autograd\\__init__.py:223\u001b[0m, in \u001b[0;36mgrad\u001b[1;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    221\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m--> 223\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    224\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    225\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in range(3):\n",
    "    selected_data = []\n",
    "    max = len(data)\n",
    "    ind_list = list(range(0, max))\n",
    "    n = 24\n",
    "    if max < n:\n",
    "        n = max\n",
    "    selected_ind = random.sample(ind_list, n)\n",
    "    selected_ind = sorted(selected_ind)\n",
    "    for ind in selected_ind:\n",
    "        selected_data.append(data[ind])\n",
    "    selected_data = np.stack(selected_data)\n",
    "\n",
    "    #data = torch.as_tensor(data, dtype=torch.float32)\n",
    "    selected_data = torch.as_tensor(selected_data, dtype=torch.float32)\n",
    "    dataset = torch.utils.data.TensorDataset(selected_data)\n",
    "    data_loader = torch.utils.data.DataLoader(\n",
    "        dataset, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "\n",
    "\n",
    "    # Create neural networks\n",
    "    discriminator = Discriminator()\n",
    "    generator = Generator()\n",
    "\n",
    "    # Create optimizers\n",
    "    d_optimizer = torch.optim.Adam(\n",
    "        discriminator.parameters(), lr=0.001,  betas=(0.5, 0.9))\n",
    "    g_optimizer = torch.optim.Adam(\n",
    "        generator.parameters(), lr=0.001, betas=(0.5, 0.9))\n",
    "\n",
    "    # Prepare the inputs for the sampler, which wil run during the training\n",
    "    sample_latent = torch.randn(n_samples, latent_dim)\n",
    "\n",
    "    # Transfer the neural nets and samples to GPU\n",
    "    if torch.cuda.is_available():\n",
    "        discriminator = discriminator.cuda()\n",
    "        generator = generator.cuda()\n",
    "        sample_latent = sample_latent.cuda()\n",
    "\n",
    "    # Create an empty dictionary to sotre history samples\n",
    "    history_samples = {}\n",
    "\n",
    "    # Create a LiveLoss logger instance for monitoring\n",
    "    liveloss = PlotLosses(outputs=[MatplotlibPlot(cell_size=(6,2))])\n",
    "\n",
    "    # Initialize step\n",
    "    step = 0\n",
    "    # Create a progress bar instance for monitoring\n",
    "    n_steps = 17000\n",
    "    progress_bar = tqdm(total=n_steps, initial=step, ncols=80, mininterval=1)\n",
    "    # Start iterations\n",
    "    while step < n_steps + 1:\n",
    "        # Iterate over the dataset\n",
    "        for real_samples in data_loader:\n",
    "            # Train the neural networks\n",
    "            generator.train()\n",
    "            d_loss, g_loss = train_one_step(d_optimizer, g_optimizer, real_samples[0])\n",
    "\n",
    "            # Record smoothened loss values to LiveLoss logger\n",
    "            if step > 0:\n",
    "                running_d_loss = 0.05 * d_loss + 0.95 * running_d_loss\n",
    "                running_g_loss = 0.05 * g_loss + 0.95 * running_g_loss\n",
    "            else:\n",
    "                running_d_loss, running_g_loss = 0.0, 0.0\n",
    "            liveloss.update({'negative_critic_loss': -running_d_loss})\n",
    "            # liveloss.update({'d_loss': running_d_loss, 'g_loss': running_g_loss})\n",
    "\n",
    "            # Update losses to progress bar\n",
    "            progress_bar.set_description_str(\n",
    "                \"(d_loss={: 8.6f}, g_loss={: 8.6f})\".format(d_loss, g_loss))\n",
    "\n",
    "            if step % sample_interval == 0:\n",
    "                # Get generated samples\n",
    "                generator.eval()\n",
    "\n",
    "                samples = generator(sample_latent).cpu().detach().numpy()\n",
    "                history_samples[step] = samples\n",
    "\n",
    "                # Display loss curves\n",
    "                clear_output(True)\n",
    "                #if step > 0:\n",
    "                    #liveloss.send()\n",
    "\n",
    "                # Display generated samples\n",
    "                samples = samples.transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)\n",
    "                tracks = []\n",
    "                for idx, (program, is_drum, track_name) in enumerate(\n",
    "                    zip(programs, is_drums, track_names)\n",
    "                ):\n",
    "                    pianoroll = np.pad(\n",
    "                        samples[idx] > 0.5,\n",
    "                        ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))\n",
    "                    )\n",
    "                    tracks.append(\n",
    "                        StandardTrack(\n",
    "                            name=track_name,\n",
    "                            program=program,\n",
    "                            is_drum=is_drum,\n",
    "                            pianoroll=pianoroll\n",
    "                        )\n",
    "                    )\n",
    "                m = Multitrack(\n",
    "                    tracks=tracks,\n",
    "                    tempo=tempo_array,\n",
    "                    resolution=beat_resolution\n",
    "                )\n",
    "                \n",
    "\n",
    "            step += 1\n",
    "            progress_bar.update(1)\n",
    "            if step >= n_steps:\n",
    "                break\n",
    "    file_name = \"Electronic_Strong_Negative\"\n",
    "    pypianoroll.write(\"midi_file/\"+file_name+str(i)+\".mid\",m)\n",
    "    # Specify a path to save to\n",
    "    PATH = \"model/\"+file_name+str(i)+\".pt\"\n",
    "    torch.save({\n",
    "                'Generator_state_dict': generator.state_dict(),\n",
    "                'Discriminator_state_dict':discriminator.state_dict(),\n",
    "                'd_optimizer_state_dict':d_optimizer.state_dict(),\n",
    "                'g_optimizer_state_dict':g_optimizer.state_dict()\n",
    "                }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0b6bb640",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load(PATH)\n",
    "modelA.load_state_dict(checkpoint['Generator_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "638ed4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_latent = torch.randn(n_samples, latent_dim)\n",
    "sample_latent = sample_latent.cuda()\n",
    "samples = generator(sample_latent).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3121a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = samples.transpose(1, 0, 2, 3).reshape(n_tracks, -1, n_pitches)\n",
    "tracks = []\n",
    "for idx, (program, is_drum, track_name) in enumerate(\n",
    "    zip(programs, is_drums, track_names)\n",
    "):\n",
    "    pianoroll = np.pad(\n",
    "        samples[idx] > 0.5,\n",
    "        ((0, 0), (lowest_pitch, 128 - lowest_pitch - n_pitches))\n",
    "    )\n",
    "    tracks.append(\n",
    "        StandardTrack(\n",
    "            name=track_name,\n",
    "            program=program,\n",
    "            is_drum=is_drum,\n",
    "            pianoroll=pianoroll\n",
    "        )\n",
    "    )\n",
    "m = Multitrack(\n",
    "    tracks=tracks,\n",
    "    tempo=tempo_array,\n",
    "    resolution=beat_resolution\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b965be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pypianoroll.write(\"MuseGan6000-9.mid\",m) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb52474e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "930919e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"# Data\\nn_tracks = 1  # number of tracks\\nn_pitches = 72  # number of pitches\\nlowest_pitch = 24  # MIDI note number of the lowest pitch\\nn_samples_per_song = 8  # number of samples to extract from each song in the datset\\nn_measures = 4  # number of measures per sample\\nbeat_resolution = 4  # temporal resolution of a beat (in timestep)\\nprograms = [0]  # program number for each track\\nis_drums = [False]  # drum indicator for each track\\ntrack_names = ['Piano']  # name of each track\\ntempo = 100\\n\\n# Training\\nbatch_size = 16\\nlatent_dim = 128\\nn_steps = 9000\\n\\n# Sampling\\nsample_interval = 100  # interval to run the sampler (in step)\\nn_samples = 4\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"# Data\n",
    "n_tracks = 1  # number of tracks\n",
    "n_pitches = 72  # number of pitches\n",
    "lowest_pitch = 24  # MIDI note number of the lowest pitch\n",
    "n_samples_per_song = 8  # number of samples to extract from each song in the datset\n",
    "n_measures = 4  # number of measures per sample\n",
    "beat_resolution = 4  # temporal resolution of a beat (in timestep)\n",
    "programs = [0]  # program number for each track\n",
    "is_drums = [False]  # drum indicator for each track\n",
    "track_names = ['Piano']  # name of each track\n",
    "tempo = 100\n",
    "\n",
    "# Training\n",
    "batch_size = 16\n",
    "latent_dim = 128\n",
    "n_steps = 9000\n",
    "\n",
    "# Sampling\n",
    "sample_interval = 100  # interval to run the sampler (in step)\n",
    "n_samples = 4\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
